# -*- coding: utf-8 -*-
"""ironiaL52_roberta.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xoOvVCE6ocZm1vaTI2dh_swzlZ_bZb4r
"""

!pip3 install --upgrade pip

!pip install gspread # acceso a google sheets
!pip install wordcloud # Dibujar nubes de palabras
!pip install rich # Ayuda visualización textual
!pip install stop_words # Lista de palabras funcionales
!pip install seaborn # Visualizació

!pip install --root-user-action=ignore -U pip setuptools wheel #Preparando para instalar spacy

!pip uninstall cupy-cuda11x

!pip install --root-user-action=ignore -U spacy[cuda102] # para lematizar
#¿Se podrá usar otro número para cuda?

!python -m spacy download es_core_news_sm  --root-user-action=ignore # modelo para lematizar

!pip install --root-user-action=ignore palettable # Paletas de colores para wordcloud
!pip install --root-user-action=ignore emoji # Procesador de emojis
!pip install --root-user-action=ignore tweet-preprocessor
!pip install --root-user-action=ignore transformers
!pip install --root-user-action=ignore datasets
!pip install --root-user-action=ignore sentencepiece

!pip install --root-user-action=ignore pandas --upgrade # actualizar pandas

!apt-get install fonts-symbola # Fuente para wordcloud

!pip install --root-user-action=ignore --upgrade accelerate

## Basic tools
from collections import Counter # Para calcular las frecuencias
import os.path # Manejo de paths
## Impresión y interacción
from rich.jupyter import print # Prints con colores
from ipywidgets import interact, interactive, fixed, interact_manual
import ipywidgets as widgets
from rich.progress import track
from rich.progress import Progress
## Manipular data
import pandas as pd # Manipular los datos
import numpy as np # Numeric manipulation
from datasets import Dataset
## Manipular texto
import preprocessor as p # Tweet cleaning
from stop_words import get_stop_words # Lista de palabras funcionales
from wordcloud import WordCloud # Nube de palabras
import emoji # Manejo de emojis
import spacy
nlp_es=spacy.load("es_core_news_sm")
import gensim.corpora as corpora
## Visualización
import matplotlib.pyplot as plt
import matplotlib as mpl
import matplotlib.font_manager as fm
import seaborn as sns

from transformers import BertForSequenceClassification, BertTokenizerFast, Trainer, TrainingArguments
import torch
import numpy as np
from sklearn.metrics import accuracy_score, precision_recall_fscore_support

import torch

#To select between CPU and GPU to execute torch

if torch.cuda.is_available():
  device = torch.device('cuda:0')
  print('GPU')
else:
  device = torch.device('cpu')
  print('CPU')

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('/content/drive/MyDrive/Servicio social/Con datos Heili/Conjunto_entr_final_con_datos_heili.csv')

#@title ↳ Filtrado  y preprocesado de datos

#@markdown Columna para usar en el análisis [INPUT]
input = "text" #@param {"type":"string"}

#@markdown Columna para usar como etiquetas [OUTPUT]
output = "label" #@param

#@markdown Para hacer más rápido escoger un segmento más corto de datos
ini = 0 #@param {"type":"integer"}
fin = 0 #@param {"type":"integer"}

#@markdown Options to process the text

#@markdown Filtrar usando una expresión regular
re_filter = "" #@param {"type":"string"}

#@markdown Pone todo en minúsculas
use_lower = False #@param {"type":"boolean"}

#@markdown Quita urls
quitar_url = True #@param {"type":"boolean"}

#@markdown Quita hashtag
quitar_hashtag = True #@param {"type":"boolean"}

#@markdown Quitar etiquetas
quitar_etiquetas = True #@param {"type":"boolean"}

#@markdown Transforma los emojis a texto
demojize = True #@param {"type":"boolean"}

if fin>0:
  df_analysis=df[ini:fin]
else:
  df_analysis=df[ini:]

# Filtering by the regutlar expression
if len(re_filter.strip())>0:
  df_analysis=df_analysis[df_analysis[input].str.contains(re_filter, regex=True)]

df_analysis["text_"]=df_analysis[input]

# If transform to lower
if use_lower:
  df_analysis["text_"]=df_analysis['text_'].apply(str.lower)

# If use_url
if quitar_url:
  def quitar_link(palabra):
    import re
    palabra = re.sub("http://.+|https://.+", 'http://link', palabra)
    return palabra
  df_analysis["text_"]=df_analysis['text_'].apply(lambda x: quitar_link(x))


#If quitar links
if quitar_hashtag:
  def quitar_hashtag(palabra):
    import re
    palabra = re.sub("#[\w]+", '', palabra)
    return palabra
  df_analysis["text_"]=df_analysis['text_'].apply(lambda x: quitar_hashtag(x))


 # If quitar etiquetas:
if quitar_etiquetas:
  def quitar_etiquetas(palabra):
    import re
    palabra = re.sub("@[\w]+", '@', palabra)
    return palabra
  df_analysis["text_"]=df_analysis['text_'].apply(lambda x: quitar_etiquetas(x))

# Emojis
if demojize:
    df_analysis["text_"]=df_analysis['text_'].apply(emoji.demojize)



# Columna para la cual crear el clasificador
df_analysis["labels"] = df_analysis[output]

print(f"[green]Colección de datos con {len(df_analysis)} registros[/]")
df_analysis.head(50)

model_name = "cardiffnlp/twitter-roberta-base-irony"  #@param {"type":"string"}


from transformers import AutoTokenizer, AutoModelForSequenceClassification

tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

#@title Configure training

output_dir = "./results" #@param {"type":"string"}
logging_dir = "./logs" #@param {"type":"string"}
eval_steps = "100" #@param {"type":"string"}
num_train_epochs = "3" #@param {"type":"string"}
batch_size_train = "16" #@param {"type":"string"}
batch_size_eval = "64" #@param {"type":"string"}

#@title  Crear conjuntos


#@markdown Train, test and validation split
random_state = 42 #@param {"type":"integer"}
train_proportion = "0.8" #@param {"type":"string"}
test_proportion = "0.1" #@param {"type":"string"}

train, test, val = \
              np.split(df_analysis.sample(frac=1, random_state=int(42)),
                       [int(float(train_proportion)*len(df)), int((float(train_proportion)+float(test_proportion))*len(df))])


train_dataset = Dataset.from_pandas(train)
test_dataset = Dataset.from_pandas(test)
val_dataset = Dataset.from_pandas(val)


# Print modified dataframe
print("[bold blue]Sizes[/]")
print("[bold]Train     : [/]",len(train_dataset))
print("[bold]Validation: [/]",len(val_dataset))
print("[bold]Test      : [/]",len(test_dataset))

def compute_metrics(pred):
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)
    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')
    acc = accuracy_score(labels, preds)
    return {
        'accuracy': acc,
        'f1': f1,
        'precision': precision,
        'recall': recall
    }

def tokenize(batch):
    return tokenizer(batch['text'], max_length=100, padding='max_length', truncation=True)

train_dataset = train_dataset.map(tokenize, batched=True)
test_dataset = test_dataset.map(tokenize, batched=True)
val_dataset = val_dataset.map(tokenize, batched=True)

train_dataset.set_format('torch', columns=['input_ids',   'attention_mask', 'label'])
test_dataset.set_format('torch', columns=['input_ids',  'attention_mask', 'label'])
val_dataset.set_format('torch', columns=['input_ids',  'attention_mask', 'label'])

training_args = TrainingArguments(
    output_dir=output_dir,
    evaluation_strategy="steps",
    num_train_epochs=int(num_train_epochs),
    warmup_steps=500,
    weight_decay=0.01,
    logging_dir=logging_dir,
    per_device_train_batch_size=int(batch_size_train),
    per_device_eval_batch_size=int(batch_size_eval),
    eval_steps=int(eval_steps),
    logging_steps=int(eval_steps),
    seed=random_state
)

trainer = Trainer(
    model=model,
    args=training_args,
    compute_metrics=compute_metrics,
    train_dataset=train_dataset,
    eval_dataset=val_dataset
)

trainer.train()

print("[blue] Full test[/]")
print(trainer.evaluate(eval_dataset=test_dataset))

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard
# %tensorboard --logdir logs

#@title Save model

save_directory= "./models_modelo_final" #@param {"type":"string"}
model_name_sufix = "entreno6_final" #@param {"type":"string"}

model.save_pretrained(save_directory=os.path.join(save_directory,os.path.basename(model_name)+model_name_sufix))
tokenizer.save_pretrained(save_directory=os.path.join(save_directory,os.path.basename(model_name)+model_name_sufix))

! ls

!zip -r modelo_ironia_final2.zip models_modelo_final

! cp  'modelo_ironia_final2.zip' "/content/drive/MyDrive/Servicio social/Con datos Heili"

df_etiquetar = pd.read_csv('/content/drive/MyDrive/Servicio social/Con datos Heili/evaluacion_sin_datos_heili.csv')

df_etiquetar

#@title ↳ Filtrado  y preprocesado de datos PARA ETIQUETADO

#@markdown Columna para usar en el análisis [INPUT]
input = "text" #@param {"type":"string"}

#@markdown Columna para usar como etiquetas [OUTPUT]
output = "label" #@param

#@markdown Para hacer más rápido escoger un segmento más corto de datos
ini = 0 #@param {"type":"integer"}
fin = 0 #@param {"type":"integer"}

#@markdown Options to process the text

#@markdown Filtrar usando una expresión regular
re_filter = "" #@param {"type":"string"}

#@markdown Pone todo en minúsculas
use_lower = False #@param {"type":"boolean"}

#@markdown Quita urls
quitar_url = True #@param {"type":"boolean"}

#@markdown Quita hashtag
quitar_hashtag = True #@param {"type":"boolean"}

#@markdown Quitar etiquetas
quitar_etiquetas = True #@param {"type":"boolean"}

#@markdown Transforma los emojis a texto
demojize = True #@param {"type":"boolean"}

if fin>0:
  df_analysis=df_etiquetar[ini:fin]
else:
  df_analysis=df_etiquetar[ini:]

# Filtering by the regutlar expression
if len(re_filter.strip())>0:
  df_analysis=df_analysis[df_analysis[input].str.contains(re_filter, regex=True)]

df_analysis["text_"]=df_analysis[input]

# If transform to lower
if use_lower:
  df_analysis["text_"]=df_analysis['text_'].apply(str.lower)

# If use_url

def quitar_link(palabra):
  import re
  palabra = re.sub("http://.+|https://.+", 'http://link', palabra)
  return palabra
df_analysis["text_"]=df_analysis['text_'].apply(lambda x: quitar_link(x))


#If quitar links

def quitar_hashtag(palabra):
  import re
  palabra = re.sub("#.+", '', palabra)
  return palabra
df_analysis["text_"]=df_analysis['text_'].apply(lambda x: quitar_hashtag(x))



 # If quitar etiquetas:

def quitar_etiquetas(palabra):
  import re
  palabra = re.sub("@[\w]+", '@', palabra)
  return palabra
df_analysis["text_"]=df_analysis['text_'].apply(lambda x: quitar_etiquetas(x))

# Emojis
if demojize:
  df_analysis["text_"]=df_analysis['text_'].apply(emoji.demojize)



# Columna para la cual crear el clasificador
#df_analysis["labels"] = df_analysis[output]

print(f"[green]Colección de datos con {len(df_analysis)} registros[/]")
df_analysis.head(50)

df_nuevo = pd.DataFrame()

df_nuevo['text'] = df_analysis['text']

df_nuevo['text_'] = df_analysis['text_']

model_name = "/content/models_modelo_final/twitter-roberta-base-ironyentreno6_final"  #@param {"type":"string"}


from transformers import AutoTokenizer, AutoModelForSequenceClassification

tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

device="cuda"
model.to(device)
model.eval()

def label(x):
  encoded_input = tokenizer(x, return_tensors='pt', max_length= 250, truncation=True)
  outputs = model(input_ids=encoded_input["input_ids"].to(device))
  resultado = int(outputs.logits.argmax(dim=-1)[0].cpu())
  return resultado

label('@ sonaste como louis jajajaa')

def softmax(z): return np.exp(z)/((np.exp(z)).sum())

def porcentaje_ironia(oracion):
    encoded_input = tokenizer(oracion, return_tensors='pt', max_length= 250)
    outputs = model(input_ids=encoded_input["input_ids"].to(device))
    predictions0 = float(torch.nn.functional.softmax(outputs.logits, dim=-1)[0][1])
    return predictions0

porcentaje_ironia('@ sonaste como louis jajajaa')

df_nuevo['label_with_model'] = df_analysis['text_'].apply(lambda x: label(x))

df_nuevo.head()

df_nuevo['porcentaje_model'] = df_analysis['text_'].apply(lambda x: porcentaje_ironia(x))

model.config.id2label

model

df_nuevo.head()

test['label_with_model'] = test['text_'].apply(lambda x: label(x))

from sklearn.metrics import accuracy_score, precision_recall_fscore_support
from sklearn import metrics
confusion_matrix = metrics.confusion_matrix(test['label'], test['label_with_model'])
cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])

import matplotlib.pyplot as plt

print('Número de tweets irónicos='+str(len(test[test['label']==1])))
print('Número de tweets no irónicos='+str(len(test[test['label']==0])))
cm_display.plot()
plt.show()

df_nuevo.to_csv('cto_etiquedado.csv')

orden = np.array(df_nuevo['porcentaje_model'])
orden = np.sort(orden)[::-1]

plt.plot(orden)
plt.show()

df_con_incertidumbre = df_nuevo[(df_nuevo['porcentaje_model']>0.25)&(df_nuevo['porcentaje_model']<0.75)]

df_con_incertidumbre.to_csv('df_con_incertidumbre.csv')